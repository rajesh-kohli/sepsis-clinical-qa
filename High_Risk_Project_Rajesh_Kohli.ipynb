{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Risk Project - Retrieval-Augmented QA system over real clinical guidelines\n",
    "#### Build a retrieval-augmented QA system over real clinical guidelines where we’ll:\n",
    "1.\tIngest PDF guidelines (e.g. sepsis management)\n",
    "2.\tChunk & embed with OpenAI’s embeddings\n",
    "3.\tIndex with FAISS\n",
    "4.\tBuild a query pipeline that retrieves the top chunks and asks GPT for a final answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Notebook Setup & PDF Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical-QA: Retrieval-Augmented System\n",
    "\n",
    "**Goal:** Ask free-text clinical questions and get grounded answers from PDF guidelines.\n",
    "\n",
    "**Outline:**\n",
    "1. Setup & imports  \n",
    "2. Load & extract PDF text  \n",
    "3. Chunking  \n",
    "4. Embedding & FAISS indexing  \n",
    "5. Query + answer  \n",
    "6. Demo & evaluation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: openai in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (0.28.0)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from openai) (3.11.16)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from requests>=2.20->openai) (2024.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from aiohttp->openai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from aiohttp->openai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from aiohttp->openai) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from aiohttp->openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from aiohttp->openai) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from aiohttp->openai) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/dl_hw/lib/python3.11/site-packages (from aiohttp->openai) (1.18.3)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2, faiss-cpu, tiktoken\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [tiktoken]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyPDF2-3.0.1 faiss-cpu-1.11.0 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# ——— 1. (Re)install needed packages ———\n",
    "!pip install PyPDF2 faiss-cpu openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ——— 2. Imports ———\n",
    "import os\n",
    "import PyPDF2\n",
    "import faiss\n",
    "import openai\n",
    "from tiktoken import get_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"OPENAI_API_KEY\" in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 17137 characters of text.\n"
     ]
    }
   ],
   "source": [
    "# ——— 3. Load a PDF from disk ———\n",
    "pdf_path = \"/Users/rajeshkohli/Documents/UT_Austin/AI_In_Healthcare/High_Risk_Project/Sepsis-Guidelines-UF-Shands.pdf\"\n",
    "reader = PyPDF2.PdfReader(pdf_path)\n",
    "raw_text = \"\\n\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "\n",
    "print(\"Extracted\", len(raw_text), \"characters of text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Chunk the PDF Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chunking the Text\n",
    "\n",
    "We’ll:\n",
    "\n",
    "1. Count tokens using the same tokenizer as our embedding model  \n",
    "2. Split the raw text into fixed-size chunks (e.g. 500 tokens) with overlap (e.g. 50 tokens)  \n",
    "3. Inspect a few chunks to make sure the splits look clean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 11\n",
      "\n",
      "--- Sample chunk [0] ---\n",
      "\n",
      " \n",
      " 1 \n",
      "  POLICY AND PROCEDURE ADULT SEVERE SEPSIS AND SEPTIC SHOCK MANAGEMENT  SUBJECT:  Guidelines for the management of Severe Sepsis and Septic Shock at Shands UF   PURPOSE:   Sepsis is recognized as a challenging disease to overcome.  The progression of sepsis to severe sepsis and septic shock is devastating yielding a mortality of 30-80%.1 In an effort to reduce the morbidity and mortality from sepsis, Shands University of Florida Hospital has committed to identify and implement “bundles.”   …\n"
     ]
    }
   ],
   "source": [
    "from tiktoken import get_encoding\n",
    "\n",
    "# 1. Select the encoding for text-embedding-ada-002\n",
    "enc = get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "def chunk_text(text: str, max_tokens=500, overlap=50):\n",
    "    tokens = enc.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + max_tokens, len(tokens))\n",
    "        chunk = enc.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        # step forward by max_tokens - overlap\n",
    "        start += max_tokens - overlap\n",
    "    return chunks\n",
    "\n",
    "# 2. Run chunking\n",
    "chunks = chunk_text(raw_text, max_tokens=500, overlap=50)\n",
    "\n",
    "# 3. Inspect results\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(\"\\n--- Sample chunk [0] ---\\n\")\n",
    "print(chunks[0][:500], \"…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Embedding & FAISS Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding & Indexing\n",
    "\n",
    "We’ll:\n",
    "\n",
    "1. Use OpenAI’s `text-embedding-ada-002` to embed each chunk  \n",
    "2. Build a FAISS index over these vectors for fast similarity search  \n",
    "3. Persist both the FAISS index and our chunk list for querying  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be305be9c43c4bbfb7340d182185861d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding chunks:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (11, 1536)\n",
      "FAISS index contains 11 vectors\n",
      "Index and chunks saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 0. Explicitly load the key into the client\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# 1. Model name\n",
    "model_name = \"text-embedding-ada-002\"\n",
    "\n",
    "# 2. Embed each chunk\n",
    "emb_list = []\n",
    "for chunk in tqdm(chunks, desc=\"Embedding chunks\"):\n",
    "    resp = openai.Embedding.create(\n",
    "        input=chunk,\n",
    "        model=model_name\n",
    "    )\n",
    "    emb_list.append(resp[\"data\"][0][\"embedding\"])\n",
    "\n",
    "# 3. Convert to numpy array\n",
    "emb_matrix = np.array(emb_list, dtype=\"float32\")\n",
    "print(\"Embeddings shape:\", emb_matrix.shape)\n",
    "\n",
    "# 4. Build FAISS index\n",
    "dim = emb_matrix.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(emb_matrix)\n",
    "print(\"FAISS index contains\", index.ntotal, \"vectors\")\n",
    "\n",
    "# 5. Save to disk\n",
    "faiss.write_index(index, \"sepsis_guideline.index\")\n",
    "with open(\"sepsis_chunks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)\n",
    "print(\"Index and chunks saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Build & Test the Query Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Question Answering\n",
    "\n",
    "We’ll:\n",
    "1. Load our FAISS index and chunk list  \n",
    "2. Embed incoming questions  \n",
    "3. Retrieve the top-k most similar chunks  \n",
    "4. Feed those chunks plus the question to OpenAI’s chat model  \n",
    "5. Return the model’s answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mortality range for severe sepsis and septic shock is 30-80%.\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, faiss, openai\n",
    "import numpy as np\n",
    "from tiktoken import get_encoding\n",
    "\n",
    "# 0. Reload your API key\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# 1. Load the saved FAISS index and chunks\n",
    "index = faiss.read_index(\"sepsis_guideline.index\")\n",
    "with open(\"sepsis_chunks.pkl\", \"rb\") as f:\n",
    "    chunks = pickle.load(f)\n",
    "\n",
    "# 2. Setup tokenizer for embeddings\n",
    "enc = get_encoding(\"cl100k_base\")\n",
    "def embed_text(text):\n",
    "    resp = openai.Embedding.create(\n",
    "        input=text, model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return np.array(resp[\"data\"][0][\"embedding\"], dtype=\"float32\")\n",
    "\n",
    "# 3. Define QA function\n",
    "def answer_question(question, k=3):\n",
    "    # 3a. Embed question\n",
    "    q_emb = embed_text(question)\n",
    "    # 3b. Retrieve top-k\n",
    "    D, I = index.search(q_emb.reshape(1, -1), k)\n",
    "    selected = [chunks[i] for i in I[0]]\n",
    "    # 3c. Build the context prompt\n",
    "    context = \"\\n\\n---\\n\\n\".join(selected)\n",
    "    system_prompt = (\n",
    "        \"You are a knowledgeable clinical assistant. \"\n",
    "        \"Use the following extracted guideline snippets to answer the question truthfully.\"\n",
    "    )\n",
    "    user_prompt = f\"CONTEXT:\\n\\n{context}\\n\\nQUESTION: {question}\"\n",
    "    # 3d. Call chat completion\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\",   \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "# 4. Test it\n",
    "print(answer_question(\"What is the mortality range for severe sepsis and septic shock?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Interactive Q&A Demo\n",
    "\n",
    "Now let’s turn this into a little interactive demo so you (or anyone) can type in a question right in the notebook and get an answer on the fly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Interactive Demo\n",
    "\n",
    "Below is a simple loop: enter any clinical question about sepsis management, and our system will retrieve relevant guideline snippets and answer it.\n",
    "Type **“exit”** to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When should vasopressors be started in septic shock?\n",
      "\n",
      "Answer:\n",
      "Vasopressors should be initiated in septic shock when the mean arterial pressure (MAP) is less than 65 mmHg or the systolic blood pressure (SBP) is less than 90 mmHg despite a fluid challenge of 20 ml/kg or 2 liters of crystalloid, or if the central venous pressure (CVP) is greater than 8 mmHg.\n"
     ]
    }
   ],
   "source": [
    "# 🔧 Ask your question here:\n",
    "question = \"When should vasopressors be started in septic shock?\"\n",
    "\n",
    "# 🔍 Get an answer:\n",
    "answer = answer_question(question, k=3)\n",
    "print(f\"Question: {question}\\n\\nAnswer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save & Publish Code\n",
    "\n",
    "We’ll push our notebook, index, and chunks to GitHub so others can reproduce our work.\n",
    "\n",
    "- Create a new repo on GitHub (e.g. `sepsis-clinical-qa`).  \n",
    "- Replace `<your-repo-url>` below with your repo’s SSH or HTTPS URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
      "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
      "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
      "\u001b[33mhint:\u001b[m\n",
      "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
      "\u001b[33mhint:\u001b[m\n",
      "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
      "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
      "\u001b[33mhint:\u001b[m\n",
      "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
      "Initialized empty Git repository in /Users/rajeshkohli/Documents/UT_Austin/AI_In_Healthcare/High_Risk_Project/.git/\n"
     ]
    }
   ],
   "source": [
    "# Initialize git (if you haven’t already)\n",
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add files\n",
    "!git add High_Risk_Project_Rajesh_Kohli.ipynb sepsis_guideline.index sepsis_chunks.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) c8fc385] Initial retrieval-augmented clinical QA pipeline\n",
      " Committer: Rajesh Kohli <rajeshkohli@Mac-90.lan>\n",
      "Your name and email address were configured automatically based\n",
      "on your username and hostname. Please check that they are accurate.\n",
      "You can suppress this message by setting them explicitly. Run the\n",
      "following command and follow the instructions in your editor to edit\n",
      "your configuration file:\n",
      "\n",
      "    git config --global --edit\n",
      "\n",
      "After doing this, you may fix the identity used for this commit with:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 3 files changed, 479 insertions(+)\n",
      " create mode 100644 High_Risk_Project_Rajesh_Kohli.ipynb\n",
      " create mode 100644 sepsis_chunks.pkl\n",
      " create mode 100644 sepsis_guideline.index\n"
     ]
    }
   ],
   "source": [
    "# Commit\n",
    "!git commit -m \"Initial retrieval-augmented clinical QA pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your GitHub repo URL and push\n",
    "!git remote add origin https://github.com/rajesh-kohli/sepsis-clinical-qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git branch -M main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 14 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 67.91 KiB | 22.63 MiB/s, done.\n",
      "Total 5 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\n",
      "remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/main.\u001b[K\n",
      "remote: \n",
      "remote: - GITHUB PUSH PROTECTION\u001b[K\n",
      "remote:   —————————————————————————————————————————\u001b[K\n",
      "remote:     Resolve the following violations before pushing again\u001b[K\n",
      "remote: \n",
      "remote:     - Push cannot contain secrets\u001b[K\n",
      "remote: \n",
      "remote:     \u001b[K\n",
      "remote:      (?) Learn how to resolve a blocked push\u001b[K\n",
      "remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n",
      "remote:     \u001b[K\n",
      "remote:     \u001b[K\n",
      "remote:       —— OpenAI API Key ————————————————————————————————————\u001b[K\n",
      "remote:        locations:\u001b[K\n",
      "remote:          - commit: c8fc385a1220514b9c884d6bd5e2dcad5b0b8877\u001b[K\n",
      "remote:            path: High_Risk_Project_Rajesh_Kohli.ipynb:110\u001b[K\n",
      "remote:     \u001b[K\n",
      "remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n",
      "remote:        https://github.com/rajesh-kohli/sepsis-clinical-qa/security/secret-scanning/unblock-secret/2wNyZRPy9wnumG4P0YE5bAirhs6\u001b[K\n",
      "remote:     \u001b[K\n",
      "remote: \n",
      "remote: \n",
      "To https://github.com/rajesh-kohli/sepsis-clinical-qa\n",
      " \u001b[31m! [remote rejected]\u001b[m main -> main (push declined due to repository rule violations)\n",
      "\u001b[31merror: failed to push some refs to 'https://github.com/rajesh-kohli/sepsis-clinical-qa'\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
